{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian mixture \n",
    "\n",
    "## $\\pi (x) = \\frac{1}{2(2\\pi)^{d/2}} \\left( e ^{\\frac{-| x-a|^2}{2}}  + e ^{\\frac{-| x+a|^2}{2}} \\right), \\quad x \\in\\mathbb R^d$\n",
    "\n",
    "$U(x) = \\frac{1}{2} \\|x - a\\|_2^2 - \\text{log}(1 + e^{-2x^\\top a})$\n",
    "\n",
    "$\\nabla U(x) = x-a +2a(1 + e^{2 x^\\top a})^{-1}$\n",
    "\n",
    "$ m = 1 - \\|a \\|_2^2 \\quad $ (strongly convex function)\n",
    "\n",
    "$M = 1 \\quad$  (Lipschitz continuous gradient)\n",
    "\n",
    "$a = (\\frac{1}{\\sqrt{2d}}, \\dots, \\frac{1}{\\sqrt{2d}})$\n",
    "\n",
    "##### Setup:\n",
    "\n",
    "d = 8\n",
    "\n",
    "n = 1000\n",
    "\n",
    "N = 50000\n",
    "\n",
    "N_train = 50\n",
    "\n",
    "N_test = 100\n",
    "\n",
    "polynomials_max_deg = 1\n",
    "\n",
    "$\\tilde{n} = 100$\n",
    "\n",
    "$f(x) = \\sum_{i=1}^{d}x_i$\n",
    "\n",
    "$K = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.misc import comb\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import hermitenorm\n",
    "from tqdm import tqdm\n",
    "from numpy.polynomial.hermite_e import HermiteE\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import minimize\n",
    "from itertools import product\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "from numpy.random import normal  \n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters inicialization, ULA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 8\n",
    "a = np.ones((d,1)) / np.sqrt(2*d)\n",
    "\n",
    "def f_grad(x):\n",
    "    return x-a+2*a/(1 + np.exp(2* (x.T @ a)))\n",
    "\n",
    "def generate_lmc(a,d,N):\n",
    "    h = 0.1\n",
    "    K = 50000\n",
    "    vkh = np.empty((K + N,d,1))\n",
    "    ksi = np.random.randn(K+N,d,1)\n",
    "    vkh[0] = (np.random.normal(0,1,d)).reshape(d,1)\n",
    "    for i in range(1,K+N):\n",
    "        grad = f_grad(vkh[i-1])\n",
    "        vkh[i] = vkh[i-1] - h*grad + np.sqrt(2*h) * ksi[i]\n",
    "    return vkh[K:], ksi[K:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2342)\n",
    "X, Z = generate_lmc(a,d, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bd8795710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(X[:,1].reshape(-1,1), 25, density=True, facecolor='g', alpha=0.75)\n",
    "x = np.linspace(-5,5,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary weighted estimator with $$f(x) = x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_weighted_estimator(X):\n",
    "    return X.sum(axis = 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted estimator =  -0.012067186009939033\n"
     ]
    }
   ],
   "source": [
    "print (\"Weighted estimator = \",local_weighted_estimator(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of N_train independent paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lmc_from_initial(x_initial,a,d,N):\n",
    "    h = 0.1\n",
    "    vkh = np.empty((N,d,1))\n",
    "    vkh_grad = np.empty((N,d,1))\n",
    "    ksi = np.random.randn(N,d,1)\n",
    "    vkh[0] = x_initial\n",
    "    for i in range(1,N):\n",
    "        grad = f_grad(vkh[i-1])\n",
    "        vkh_grad[i-1] = grad\n",
    "        vkh[i] = vkh[i-1] - h*grad + np.sqrt(2*h) * ksi[i]\n",
    "    vkh_grad[-1] = f_grad(vkh[-1])\n",
    "    return vkh, ksi, vkh_grad\n",
    "\n",
    "\n",
    "def generate_paths(x_initial,N_train,a,d,N):\n",
    "    XX = []\n",
    "    ZZ = []\n",
    "    GG = []\n",
    "    for i in range(N_train):\n",
    "        X, Z, G = generate_lmc_from_initial(x_initial[-i],a,d,N)\n",
    "        XX.append(X)\n",
    "        ZZ.append(Z)\n",
    "        GG.append(G)\n",
    "    return np.array(XX),np.array(ZZ), np.array(GG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "XX, ZZ, _ = generate_paths(X,100,a,d,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate validation path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_validate, Z_validate, _= generate_lmc_from_initial(X[-5000],a,d,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(X_validate[:,1].reshape(-1,1), 20, density=True, facecolor='g', alpha=0.75)\n",
    "x = np.linspace(-5,5,100)\n",
    "plt.title((local_weighted_estimator(X_validate)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (normalized) Hermite polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_k_vec(d, K):\n",
    "    r = list(range(K+1))\n",
    "    k = []\n",
    "    for roll in product(r, repeat = d):\n",
    "        k.append(list(roll))\n",
    "    k.remove([0,0,0,0,0,0,0,0])\n",
    "    return k\n",
    "def H(k, x):\n",
    "    h = hermitenorm(k)(x) /  np.sqrt(math.factorial(k))\n",
    "    return h\n",
    "def Hermite_val(k_vec,x_vec):\n",
    "    P = 1.0\n",
    "    d = x_vec.shape[0]\n",
    "    for i in range(d):\n",
    "        P = P * H(k_vec[i],x_vec[i])\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_comb = np.zeros((2 * d,d), dtype=np.int16)\n",
    "for i in range(d):\n",
    "    k_comb[i,i] = 1\n",
    "for i in range(d):\n",
    "    k_comb[d + i,i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting linear regression for \n",
    "\n",
    "## $Q_{p,l}(x) = \\mathbb{E} \\left[f(X_p) | X_l = x\\right] = G_{p-l}(x) = \\mathbb{E} \\left[ f(\\varPhi ^{p-l} (x, \\xi))\\right]$\n",
    "\n",
    "\n",
    "### $\\forall l: \\quad G_r(x) = \\mathbb{E} \\left[f(X_{l+r}) | X_l = x \\right] $\n",
    "\n",
    "### Algorithm (trajectory + all variations):\n",
    "\n",
    "## $\\hat{G}_r = argmin_{\\psi \\in \\Psi} \\sum_{s = 1}^{N_{train}} \\sum_{l = N + 1}^{N+n-r} \\left| f(X_{l+r}^{(s)}) - \\psi(X_l^{(s)})\\right|^2$\n",
    "\n",
    "### where $\\quad  1 \\leq r \\leq n-1$\n",
    "\n",
    "## $\\hat{G}_0(x) = f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pol_ar_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_pol = 17\n",
    "def pol_ar_1d(x): #x.shape = (8,1)\n",
    "    return np.array([1,x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[0],x[1]**2,x[2]**2,x[3]**2,x[4]**2,\n",
    "                     x[5]**2,x[6]**2,x[7]]**2)\n",
    "\n",
    "def generate_X(XX, l):\n",
    "    N_train = XX.shape[0]\n",
    "    N = XX.shape[1]\n",
    "    d = XX.shape[2]\n",
    "    X = np.empty((N_train, deg_pol))\n",
    "    X[:,0] = np.ones(N_train)\n",
    "    X[:,1] = XX[:,l,0].squeeze()\n",
    "    X[:,2] = XX[:,l,1].squeeze()\n",
    "    X[:,3] = XX[:,l,2].squeeze()\n",
    "    X[:,4] = XX[:,l,3].squeeze()\n",
    "    X[:,5] = XX[:,l,4].squeeze()\n",
    "    X[:,6] = XX[:,l,5].squeeze()\n",
    "    X[:,7] = XX[:,l,6].squeeze()\n",
    "    X[:,8] = XX[:,l,7].squeeze()\n",
    "    \n",
    "    X[:,9] = (XX[:,l,0]**2).squeeze()\n",
    "    X[:,10] = (XX[:,l,1]**2).squeeze()\n",
    "    X[:,11] = (XX[:,l,2]**2).squeeze()\n",
    "    X[:,12] = (XX[:,l,3]**2).squeeze()\n",
    "    X[:,13] = (XX[:,l,4]**2).squeeze()\n",
    "    X[:,14] = (XX[:,l,5]**2).squeeze()\n",
    "    X[:,15] = (XX[:,l,6]**2).squeeze()\n",
    "    X[:,16] = (XX[:,l,7]**2).squeeze()\n",
    "\n",
    "    return X \n",
    "\n",
    "\n",
    "def generate_y(XX,ZZ,l,n_tilde = 60):\n",
    "    N_train = XX.shape[0]\n",
    "    N = XX.shape[1]\n",
    "    d = XX.shape[2]\n",
    "    y = np.zeros(N_train)\n",
    "    for s in range(N_train):\n",
    "        y[s] = XX[s][l:l+n_tilde].sum()\n",
    "    return y\n",
    "\n",
    "def q_l_fit(XX,ZZ):\n",
    "    N_train = XX.shape[0]\n",
    "    N = XX.shape[1]\n",
    "    d = XX.shape[2]\n",
    "    Betas = np.zeros((N,deg_pol))\n",
    "    for l in tqdm(range (N)):\n",
    "        X = generate_X(XX,l)\n",
    "        y = generate_y(XX,ZZ,l)\n",
    "        beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        Betas[l] = beta\n",
    "    return Betas\n",
    "\n",
    "def q_l_predict(x,l, Betas,k):\n",
    "    x_pol = pol_ar_1d(x)\n",
    "    beta = Betas[l]\n",
    "    return (x_pol @ beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Betas = q_l_fit(XX,ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.zeros((2 * d+1,d), dtype=np.int16)\n",
    "for i in range(1,d+1):\n",
    "    degrees[i,i-1] = 1\n",
    "for i in range(1,d+1):\n",
    "    degrees[d +i,i-1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_lk(X,l,k_vec, Betas):\n",
    "    d = 8\n",
    "    h = 0.1\n",
    "    S = 0\n",
    "    x_hat = X[l-1] - h*f_grad(X[l-1])\n",
    "    Small_s = np.zeros(d)\n",
    "    for ind,deg in enumerate(degrees):\n",
    "        Small_s[:] = 0\n",
    "        for d, i in enumerate(deg):\n",
    "            for t in range (i+1):\n",
    "                for s in range (int(t/2 +1)):\n",
    "                    if (k_vec[d] == t - 2*s):\n",
    "                        Small_s[d] = Small_s[d] + comb(N=i, k = t, exact = True) * x_hat[0]**(i-t) * \\\n",
    "                        math.factorial(t)*1/math.factorial(s)*1 / np.sqrt(math.factorial(t-2*s)) *np.sqrt(2*h)**t /2**s\n",
    "                    else:\n",
    "                        pass\n",
    "        S = S + Betas[l,ind] * Small_s.prod()\n",
    "    return S\n",
    "\n",
    "def M_bias(k_vec,X,Z, Betas):\n",
    "    N = X.shape[0]\n",
    "    S = 0\n",
    "    for l in range (N):\n",
    "        s = a_lk(X,l,k_vec, Betas)* Hermite_val(k_vec,Z[l])\n",
    "        S = S + s\n",
    "    return S/N\n",
    "\n",
    "def estimator_bias(k,XX,ZZ,Betas,first, last):\n",
    "    M_results = Parallel(n_jobs=-1)(delayed(M_bias)(k,XX[i],ZZ[i],Betas)for i in range(first, last))\n",
    "    return np.array(M_results).reshape(-1)\n",
    "\n",
    "def estimator(XX):\n",
    "    Pi = np.empty(XX.shape[0])\n",
    "    for i in tqdm(range(XX.shape[0])):\n",
    "        Pi[i] = local_weighted_estimator(XX[i])\n",
    "    return Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check formula ( full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_a_lk = []\n",
    "for i in range (1,XX.shape[1]):\n",
    "    plot_a_lk.append(a_lk(XX[0],i,k_comb[-1], Betas))\n",
    "plot_a_lk = np.array(plot_a_lk)\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(plot_a_lk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = XX[27]\n",
    "Z = ZZ[27]\n",
    "time_1 = timeit.default_timer()\n",
    "print (\"P =\",local_weighted_estimator(X))\n",
    "for i in range(len(k_comb)):\n",
    "    print (\"M ({}) = {} [Time:{}]\".format(k_comb[i],M_bias(k_comb[i],X,Z,Betas),timeit.default_timer()-time_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_1 = timeit.default_timer()\n",
    "print (\"P =\",local_weighted_estimator(X_validate))\n",
    "for i in range(len(k_comb)):\n",
    "    print (\"M ({}) = {} [Time:{}]\".format(k_comb[i],M_bias(k_comb[i],X_validate,Z_validate,Betas),\n",
    "                                           timeit.default_timer()-time_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = XX[27]\n",
    "Z = ZZ[27]\n",
    "time_1 = timeit.default_timer()\n",
    "print (\"P =\",local_weighted_estimator(X))\n",
    "for i in range(len(k_comb)):\n",
    "    print (\"M ({}) = {} [Time:{}]\".format(k_comb[i],M_bias(k_comb[i],X,Z,Betas),timeit.default_timer()-time_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(987)\n",
    "X, Z = generate_lmc(a,d,100000)\n",
    "XX_test, ZZ_test, GG_test = generate_paths(X,100,a,d,1000)\n",
    "P_test = estimator(XX_test)\n",
    "\n",
    "print ('Variance of Pi = ',P_test.var(dtype=np.float64,ddof = 1))\n",
    "\n",
    "# np.save('GM_8d_XX_test.npy', XX_test)\n",
    "# np.save('GM_8d_ZZ_test.npy', ZZ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XX_test = np.load('GM_8d_XX_test.npy')\n",
    "# ZZ_test = np.load('GM_8d_ZZ_test.npy')\n",
    "# P_test = estimator(XX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_results_algo_2 = np.empty((len(k_comb), XX_test.shape[0]))\n",
    "\n",
    "for i,k in enumerate(k_comb):\n",
    "    M_results_algo_2[i] = estimator_bias(k,XX_test,ZZ_test,Betas, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_results_algo_1 = np.load('../VR-MCMC/Gaussian_mixture_8d(truncated)/GM(2d)_M_results_test_.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Variance of Pi = ',(P_test - M_results_algo_1.sum(axis = 0)).var(ddof = 1))\n",
    "print ('Variance of Pi = ',(P_test - M_results_algo_2.sum(axis = 0)).var(ddof = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('c = ',P_test.var(dtype=np.float64,ddof = 1) / (P_test - M_results_algo_1.sum(axis = 0)).var(ddof = 1))\n",
    "print ('c = ',P_test.var(dtype=np.float64,ddof = 1) / (P_test - M_results_algo_2[:8].sum(axis = 0)).var(ddof = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_results_algo_1 = np.load('../VR-MCMC/Gaussian_mixture_8d(truncated)/GM(2d)_M_results_test_.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Variance of Pi = ',(P_test - M_results_algo_1.sum(axis = 0)).var(ddof = 1))\n",
    "print ('Variance of Pi = ',(P_test - M_results_algo_2.sum(axis = 0)).var(ddof = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('c = ',P_test.var(dtype=np.float64,ddof = 1) / (P_test - M_results_algo_1.sum(axis = 0)).var(ddof = 1))\n",
    "print ('c = ',P_test.var(dtype=np.float64,ddof = 1) / (P_test - M_results_algo_2.sum(axis = 0)).var(ddof = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(P_test.reshape(-1,1),18, facecolor='r', density=True,\n",
    "                            alpha=1, label=\"Distribution of $\\pi$\")\n",
    "\n",
    "plt.hist((P_test-M_results_algo_1.sum(axis = 0)).reshape(-1,1), 18, density=True, facecolor='g', \n",
    "                            alpha=0.85, label=\"Distribution of $\\pi - M^1_N$\")\n",
    "\n",
    "plt.hist((P_test-M_results_algo_2.sum(axis = 0)).reshape(-1,1), 18, density=True, facecolor='gold', \n",
    "                            alpha=0.65, label=\"Distribution of $\\pi - M^1_N$\")\n",
    "plt.grid(linestyle='-', linewidth=0.2, color='black')\n",
    "plt.tick_params(\n",
    "    axis='y',\n",
    "    color = 'w',\n",
    "    labelcolor = 'w',\n",
    "    which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# generate some random test data\n",
    "all_data = [P_test, P_test - M_results_algo_1.sum(axis = 0), P_test - M_results_algo_2.sum(axis = 0)]\n",
    "\n",
    "# plot violin plot\n",
    "plt.boxplot(all_data)\n",
    "# plt.title('')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,12))\n",
    "plt.violinplot(\n",
    "        all_data, showmeans=True, showmedians=False)\n",
    "# plt.title('violin plot')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV & ZV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZVpolyOne(traj, traj_grad):\n",
    "    n, d = traj.shape\n",
    "    samples = traj.sum(axis = 1).reshape(-1,1)\n",
    "    cov1 = np.cov(traj_grad, rowvar=False)\n",
    "    A = np.linalg.inv(cov1)\n",
    "    covariance = np.cov(np.concatenate((-traj_grad, samples), axis=1), rowvar=False)\n",
    "    paramZV1 = -np.dot(A,covariance[:d, d:])\n",
    "    ZV1 = samples - np.dot(traj_grad, paramZV1)\n",
    "    mean_ZV1 = np.mean(ZV1, axis = 0)\n",
    "    return mean_ZV1\n",
    "\n",
    "def ZVpolyTwo(traj, traj_grad):\n",
    "    n, d = traj.shape\n",
    "    samples = traj.sum(axis = 1).reshape(-1,1)\n",
    "    Lpoisson = np.zeros((n,int(d*(d+3)/2)))\n",
    "    Lpoisson[:,np.arange(d)] = - traj_grad\n",
    "    Lpoisson[:,np.arange(d, 2*d)] = 2*(1. - np.multiply(traj, traj_grad))\n",
    "    k=2*d\n",
    "    for j in np.arange(d-1):\n",
    "        for i in np.arange(j+1,d):\n",
    "            Lpoisson[:,k] = -np.multiply(traj_grad[:,i], traj[:,j])-np.multiply(traj_grad[:,j], traj[:,i])\n",
    "            k=k+1\n",
    "    \n",
    "    cov1 = np.cov(Lpoisson, rowvar=False)\n",
    "    A = np.linalg.inv(cov1)\n",
    "    cov2 = np.cov(np.concatenate((Lpoisson, samples),axis=1), rowvar=False)\n",
    "    B = cov2[0:int(d*(d+3)/2), int(d*(d+3)/2):]\n",
    "    paramZV2 = - np.dot(A,B)\n",
    "    ZV2 = samples + np.dot(Lpoisson, paramZV2)\n",
    "    mean_ZV2 = np.mean(ZV2, axis = 0)\n",
    "    return mean_ZV2\n",
    "\n",
    "def CVpolyOne(traj,traj_grad):\n",
    "    n, d = traj.shape\n",
    "    samples = traj.sum(axis = 1).reshape(-1,1)\n",
    "    covariance = np.cov(np.concatenate((traj, samples), axis=1), rowvar=False)\n",
    "    paramCV1 = covariance[:d, d:]\n",
    "    CV1 = samples - np.dot(traj_grad, paramCV1)\n",
    "    mean_CV1 = np.mean(CV1, axis = 0)\n",
    "    return mean_CV1\n",
    "\n",
    "def CVpolyTwo(traj, traj_grad):\n",
    "    n, d = traj.shape\n",
    "    samples = traj.sum(axis = 1).reshape(-1,1)\n",
    "    poisson = np.zeros((n,int(d*(d+3)/2)))\n",
    "    poisson[:,np.arange(d)] = traj\n",
    "    poisson[:,np.arange(d, 2*d)] = np.multiply(traj, traj)\n",
    "    k = 2*d\n",
    "    for j in np.arange(d-1):\n",
    "        for i in np.arange(j+1,d):\n",
    "            poisson[:,k] = np.multiply(traj[:,i], traj[:,j])\n",
    "            k=k+1\n",
    "    Lpoisson = np.zeros((n,int(d*(d+3)/2)))\n",
    "    Lpoisson[:,np.arange(d)] = - traj_grad\n",
    "    Lpoisson[:,np.arange(d, 2*d)] = 2*(1. - np.multiply(traj, traj_grad))\n",
    "    k=2*d\n",
    "    for j in np.arange(d-1):\n",
    "        for i in np.arange(j+1,d):\n",
    "            Lpoisson[:,k] = -np.multiply(traj_grad[:,i], traj[:,j]) \\\n",
    "                    -np.multiply(traj_grad[:,j], traj[:,i])\n",
    "            k=k+1\n",
    "    \n",
    "    cov1 = np.cov(np.concatenate((poisson, -Lpoisson), axis=1), rowvar=False)\n",
    "    A = np.linalg.inv(cov1[0:int(d*(d+3)/2), int(d*(d+3)/2):d*(d+3)])\n",
    "    cov2 = np.cov(np.concatenate((poisson, samples),axis=1), rowvar=False)\n",
    "    B = cov2[0:int(d*(d+3)/2), int(d*(d+3)/2):]\n",
    "    paramCV2 = np.dot(A,B)\n",
    "    CV2 = samples + np.dot(Lpoisson, paramCV2)\n",
    "    mean_CV2 = np.mean(CV2, axis = 0)\n",
    "    return mean_CV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_zv_1 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_zv_1.append(ZVpolyOne(XX_test[i].reshape(-1,d), GG_test[i].reshape(-1,d)))\n",
    "res_zv_1 = np.array(res_zv_1).reshape(-1)\n",
    "\n",
    "res_zv_2 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_zv_2.append(ZVpolyTwo(XX_test[i].reshape(-1,d), GG_test[i].reshape(-1,d)))\n",
    "res_zv_2 = np.array(res_zv_2).reshape(-1)\n",
    "\n",
    "res_cv_1 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_cv_1.append(CVpolyOne(XX_test[i].reshape(-1,d), GG_test[i].reshape(-1,d)))\n",
    "res_cv_1 = np.array(res_cv_1).reshape(-1)\n",
    "\n",
    "res_cv_2 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_cv_2.append(CVpolyTwo(XX_test[i].reshape(-1,d), GG_test[i].reshape(-1,d)))\n",
    "res_cv_2 = np.array(res_cv_2).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.append(res_zv_1)\n",
    "all_data.append(res_zv_2)\n",
    "all_data.append(res_cv_1)\n",
    "all_data.append(res_cv_2) \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.boxplot(all_data)\n",
    "plt.xticks(np.arange(1,8), ('pi', 'CV_B_1','CV_B_2', 'ZV_1', 'ZV_2', 'CV_1', 'CV_2'))\n",
    "plt.title('Boxplot')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.violinplot(\n",
    "        all_data, showmeans=True, showmedians=False)\n",
    "plt.title('violin plot')\n",
    "plt.xticks(np.arange(1,8), ('pi', 'CV_B_1','CV_B_2', 'ZV_1', 'ZV_2', 'CV_1', 'CV_2'))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
