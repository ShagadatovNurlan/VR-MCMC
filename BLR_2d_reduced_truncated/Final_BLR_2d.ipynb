{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression (dim = 2)\n",
    "\n",
    "N = 1000\n",
    "\n",
    "N_train = 500\n",
    "\n",
    "N_test = 200\n",
    "\n",
    "polynomials_max_deg = 3\n",
    "\n",
    "$f(\\theta) = \\theta_1 + \\theta_2 $\n",
    "\n",
    "$K=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "from scipy.stats import bernoulli\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.misc import comb\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.special import hermitenorm\n",
    "from tqdm import tqdm\n",
    "from numpy.polynomial.hermite_e import HermiteE\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import minimize\n",
    "from itertools import product\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "from numpy.random import normal  \n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLR data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = 2\n",
    "def r(theta, x):\n",
    "    return np.exp(theta.T @ x)/(1+np.exp(theta.T @ x))\n",
    "def generate_data(p, n):\n",
    "    X = np.empty((n,p))\n",
    "    Y = np.empty(n)\n",
    "    for i in range(n):\n",
    "        prob = multivariate_normal.rvs(0,1,p)\n",
    "        X[i, prob < 0] = -1\n",
    "        X[i, prob >= 0] = +1\n",
    "        X[i] = X[i]/np.linalg.norm(X[i])\n",
    "        Y[i] = bernoulli.rvs(r(np.ones(p),X[i].reshape(p,1)))\n",
    "    return X,Y.reshape((n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(55)\n",
    "X_reg, Y_reg = generate_data(2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma(X):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    S = np.zeros((p,p))\n",
    "    for i in range(n):\n",
    "        S = S + X[i].reshape((p,1)) @ X[i].reshape(1,p)\n",
    "    return S \n",
    "    \n",
    "def f_grad(theta, X, Y, Sigma):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    lambda_c = 3*p / np.pi**2\n",
    "    LOG = np.zeros((p,1))\n",
    "    for i in range(n):\n",
    "        LOG = LOG + X[i].reshape((p,1)) / (1+np.exp(theta.T @ X[i].reshape((p,1))))\n",
    "    F = X.T @ Y - LOG + lambda_c * Sigma @ theta\n",
    "    return F\n",
    "\n",
    "def MLE(X,Y,Sigma):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    lambda_c = 3*p / np.pi**2\n",
    "    eps = 1e-6\n",
    "    mu = np.max(np.linalg.eigvals(Sigma))\n",
    "    M = (lambda_c + 0.25*n) * mu\n",
    "    theta_k =[]\n",
    "    theta_k.append(np.ones((p,1)))\n",
    "    theta_k.append(theta_k[0] - 1/(2*M) * f_grad(theta_k[0],X,Y,Sigma))\n",
    "    i = 2\n",
    "    while(np.linalg.norm(theta_k[i-1] - theta_k[i-2])**2 > eps**2):\n",
    "        theta_k.append(theta_k[i-1] - 1/(2*M) * f_grad(theta_k[i-1],X,Y,Sigma))\n",
    "        i = i+1\n",
    "    return theta_k[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE estimator of parameter vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25514325],\n",
       "       [-0.33595237]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma = sigma(X_reg)\n",
    "MLE(X_reg,Y_reg,Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters inicialization, ULA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lmc_regression_without_precond(X,Y,Sigma, N):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]   \n",
    "    h = 0.01\n",
    "    K = 10000\n",
    "    #-----------------------------------------------------\n",
    "    vkh = np.empty((K + N,p,1), dtype=np.float64)\n",
    "    ksi = multivariate_normal.rvs(np.zeros(p), np.eye(p),K+N).reshape(K+N, p,1)\n",
    "    vkh[0] = (np.random.normal(0,1,p)).reshape(p,1)\n",
    "    for i in range(1,K+N):\n",
    "        grad = f_grad(vkh[i-1], X,Y,Sigma)\n",
    "        vkh[i] = vkh[i-1] - h*grad + np.sqrt(2*h) * ksi[i]\n",
    "    return vkh, ksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X, Z = lmc_regression_without_precond(X_reg,Y_reg,Sigma, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJCCAYAAAAC4omSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d67420898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(X[:,0].reshape(-1,1), 45, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJCCAYAAAAC4omSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKwCAEmEFAFAirAAASoQVAEDJ/wEJh1NLGrN8yAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d674204e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(X[:,1].reshape(-1,1), 45, density=True, facecolor='g', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary weighted estimator with $$f(x_1, x_2) = e^{-x_1} + 7x_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def local_weighted_estimator(X):\n",
    "    return (X[:,0] + X[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted estimator =  -0.593777630512\n"
     ]
    }
   ],
   "source": [
    "print (\"Weighted estimator = \",local_weighted_estimator(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of N_train independent paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_lmc_from_initial(x_initial,Sigma,N):\n",
    "    h = 0.01\n",
    "    vkh = np.empty((N,d,1))\n",
    "    ksi = np.random.randn(N,d,1)\n",
    "    vkh[0] = x_initial\n",
    "    for i in range(1,N):\n",
    "        grad = f_grad(vkh[i-1], X_reg,Y_reg,Sigma)\n",
    "        vkh[i] = vkh[i-1] - h*grad + np.sqrt(2*h) * ksi[i]\n",
    "    return vkh, ksi\n",
    "\n",
    "def generate_paths(x_initial,N_train,Sigma,N):\n",
    "    XX = []\n",
    "    ZZ = []\n",
    "    for i in range(N_train):\n",
    "        X, Z = generate_lmc_from_initial(x_initial[-i],Sigma,N)\n",
    "        XX.append(X)\n",
    "        ZZ.append(Z)\n",
    "    return np.array(XX),np.array(ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "XX, ZZ = generate_paths(X,50,Sigma,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (normalized) Hermite polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_k_vec(d, K):\n",
    "    r = list(range(K+1))\n",
    "    k = []\n",
    "    for roll in product(r, repeat = d):\n",
    "        k.append(list(roll))\n",
    "    k.remove([0,0])\n",
    "    return k\n",
    "def H(k, x):\n",
    "    h = hermitenorm(k)(x) /  np.sqrt(math.factorial(k))\n",
    "    return h\n",
    "def Hermite_val(k_vec,x_vec):\n",
    "    P = 1.0\n",
    "    d = x_vec.shape[0]\n",
    "    for i in range(d):\n",
    "        P = P * H(k_vec[i],x_vec[i])\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 0], [1, 1]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_comb = generate_k_vec(d,1)\n",
    "k_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting linear regression for $Q_{p,l}(x) = \\mathbb{E} \\left[f(X_p) | X_l = x\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pol_ar_1d(x): #x.shape = (2,1)\n",
    "    return np.array([1,x[0],x[1],x[0]*x[1],x[0]**2,x[1]**2,x[0]**2 *x[1],x[0]* x[1]**2, x[0]**3, x[1]**3])\n",
    "\n",
    "def generate_X_reduced(XX, r):\n",
    "    N_train = XX.shape[0]\n",
    "    N = XX.shape[1]\n",
    "    X = np.empty((N_train * (N-r) ,10))\n",
    "    all_points = XX[:, :N-r].reshape(-1,2)\n",
    "    X[:,0] = np.ones(N_train * (N-r))\n",
    "    X[:,1] = all_points[:,0].squeeze()\n",
    "    X[:,2] =all_points[:,1].squeeze()\n",
    "    X[:,3] = (all_points[:,0] * all_points[:,1]).squeeze()\n",
    "    X[:,4] = (all_points[:,0]**2).squeeze()\n",
    "    X[:,5] = (all_points[:,1]**2).squeeze()\n",
    "    X[:,6] = (all_points[:,0]**2 * all_points[:,1]).squeeze()\n",
    "    X[:,7] = (all_points[:,0] * all_points[:,1]**2).squeeze()\n",
    "    X[:,8] = (all_points[:,0]**3).squeeze()\n",
    "    X[:,9] = (all_points[:,1]**3).squeeze()\n",
    "    return X \n",
    "\n",
    "\n",
    "def generate_y_reduced(XX,r):\n",
    "    N_train = XX.shape[0]\n",
    "    N = XX.shape[1]\n",
    "    y = np.zeros(N_train * (N-r))\n",
    "    y = XX[:, r:].sum(axis = 2).reshape(-1)\n",
    "    return y\n",
    "\n",
    "def G_pml_fit(XX):\n",
    "    N_train = XX.shape[0]\n",
    "    N = XX.shape[1]\n",
    "    Betas = np.zeros((N,10))\n",
    "    for r in tqdm(range(N)):\n",
    "        X = generate_X_reduced(XX,r)\n",
    "        y = generate_y_reduced(XX,r)\n",
    "        beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        Betas[r] = beta\n",
    "    return Betas\n",
    "\n",
    "def G_pml_predict(x,pml,Betas):\n",
    "    x_pol = pol_ar_1d(x)\n",
    "    beta = Betas[pml]\n",
    "    return (x_pol @ beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 114.79it/s]\n"
     ]
    }
   ],
   "source": [
    "Betas = G_pml_fit(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('BLR_XX.npy',XX)\n",
    "np.save('BLR_ZZ.npy',ZZ)\n",
    "np.save('BLR_Betas.npy',Betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Betas = np.load('BLR_Betas.npy')\n",
    "# XX = np.load('BLR_XX.npy')\n",
    "# ZZ = np.load('BLR_ZZ.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = np.array([[0,0],[1,0],[0,1],[1,1],[2,0],[0,2],[2,1],[1,2],[3,0],[0,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def a_plk(X,p,l,k_vec):\n",
    "    h = 0.01\n",
    "    S = 0\n",
    "    x_hat = X[l-1] - h*f_grad(X[l-1],X_reg,Y_reg,Sigma)\n",
    "    for ind,(i,j) in enumerate(degrees):\n",
    "        S_small_1 = 0\n",
    "        S_small_2 = 0\n",
    "        for t in range (i+1):\n",
    "            for s in range (int(t/2 +1)):\n",
    "                if (k_vec[0] == t - 2*s):\n",
    "                    S_small_1 = S_small_1 + comb(N=i, k = t, exact = True) * x_hat[0]**(i-t) * \\\n",
    "                    math.factorial(t)*1/math.factorial(s)*1 / np.sqrt(math.factorial(t-2*s)) *np.sqrt(2*h)**t /2**s\n",
    "                else:\n",
    "                    pass\n",
    "        for t in range (j+1):\n",
    "            for s in range (int(t/2 +1)):\n",
    "                if (k_vec[1] == t - 2*s):\n",
    "                    S_small_2 = S_small_2 + comb(N=j, k = t, exact = True) * x_hat[1]**(j-t) * \\\n",
    "                    math.factorial(t)*1/math.factorial(s)*1 / np.sqrt(math.factorial(t-2*s)) *np.sqrt(2*h)**t /2**s\n",
    "                else:\n",
    "                    pass\n",
    "        S = S + Betas[p-l,ind] * S_small_1 *S_small_2\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 37882.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance of weighted estimator (1.4) on training sample: 0.000271329558705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def estimator(XX):\n",
    "    Pi = np.empty(XX.shape[0])\n",
    "    for i in tqdm(range(XX.shape[0])):\n",
    "        Pi[i] = local_weighted_estimator(XX[i])\n",
    "    return Pi\n",
    "\n",
    "P = estimator(XX)\n",
    "print (\"variance of weighted estimator (1.4) on training sample:\",P.var(ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def M_bias(k_vec,X,Z,Betas):\n",
    "    N = X.shape[0]\n",
    "    S = 0\n",
    "    for p in range(N):\n",
    "        for l in range (p+1):\n",
    "            if (p-l<100):\n",
    "                s = a_plk(X,p,l,k_vec)* Hermite_val(k_vec,Z[l])\n",
    "                S = S + s\n",
    "    return S/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimator_bias(k,XX,ZZ,Betas,first, last):\n",
    "    M_results = Parallel(n_jobs=-1)(delayed(M_bias)(k,XX[i],ZZ[i],Betas)for i in range(first, last))\n",
    "    return np.array(M_results).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = -0.602861185496\n",
      "M ([0, 1]) = [-0.01070166] [Time:119.20979213598184]\n",
      "M ([1, 0]) = [-0.00015962] [Time:237.26866157189943]\n",
      "M ([1, 1]) = [ 0.0005698] [Time:347.614896000945]\n"
     ]
    }
   ],
   "source": [
    "X = XX[7]\n",
    "Z = ZZ[7]\n",
    "time_1 = timeit.default_timer()\n",
    "print (\"P =\",local_weighted_estimator(X))\n",
    "for i in range(len(k_comb)):\n",
    "    print (\"M ({}) = {} [Time:{}]\".format(k_comb[i],M_bias(k_comb[i],X,Z,Betas),timeit.default_timer()-time_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P = -0.585765631363\n",
      "M ([0, 1]) = [ 0.01419607] [Time:118.2644731530454]\n",
      "M ([1, 0]) = [-0.00358751] [Time:235.49354022101033]\n",
      "M ([1, 1]) = [ 0.00022088] [Time:345.0952588500222]\n"
     ]
    }
   ],
   "source": [
    "X = XX[8]\n",
    "Z = ZZ[8]\n",
    "time_1 = timeit.default_timer()\n",
    "print (\"P =\",local_weighted_estimator(X))\n",
    "for i in range(len(k_comb)):\n",
    "    print (\"M ({}) = {} [Time:{}]\".format(k_comb[i],M_bias(k_comb[i],X,Z,Betas,i),timeit.default_timer()-time_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2706.88it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9651)\n",
    "X, Z = lmc_regression_without_precond(X_reg,Y_reg,Sigma, 10000)\n",
    "\n",
    "XX_test, ZZ_test =  generate_paths(X,200,Sigma,1000)\n",
    "\n",
    "P_test = estimator(XX_test)\n",
    "\n",
    "np.save('BLR_XX_test', XX_test)\n",
    "np.save('BLR_ZZ_test', ZZ_test)\n",
    "# XX_test = np.load('BLR_XX_test.npy')\n",
    "# ZZ_test = np.load('BLR_ZZ_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1000, 2, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_1 = estimator_bias(k_comb[0],XX_test,ZZ_test,Betas, 0, 200)\n",
    "np.save('BLR_M_results_test_1.npy', M_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_2 = estimator_bias(k_comb[1],XX_test,ZZ_test,Betas, 0, 200)\n",
    "np.save('BLR_M_results_test_2.npy', M_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_3 = estimator_bias(k_comb[2],XX_test,ZZ_test,Betas, 0, 200)\n",
    "np.save('BLR_M_results_test_3.npy', M_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of Pi =  0.037267758804886975\n",
      "-----------------------------------------------------\n",
      "Variance of new estimator (K=1)=  0.0026901668800894444\n",
      "=====================================================\n",
      "Variance of new estimator (K=1)=  0.0018186343098094962\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "print ('Variance of Pi = ',P_test.var(ddof = 1))\n",
    "print ('-----------------------------------------------------')\n",
    "print ('Variance of new estimator (K=1)= ',(P_test-M_1 - M_2 - M_3).var(ddof = 1))\n",
    "print (\"=====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e0170f6cdf29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m n, bins, patches = plt.hist(P_test.reshape(-1,1),18, facecolor='r', density=True,\n\u001b[0m\u001b[1;32m      3\u001b[0m                             alpha=1, label=\"Distribution of $\\pi$\")\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m n, bins, patches = plt.hist((P_test-M_1-M_2 - M_3).reshape(-1,1), 18, density=True, facecolor='y', \n",
      "\u001b[0;31mNameError\u001b[0m: name 'P_test' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6470321550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "n, bins, patches = plt.hist(P_test.reshape(-1,1),18, facecolor='r', density=True,\n",
    "                            alpha=1, label=\"Distribution of $\\pi$\")\n",
    "\n",
    "n, bins, patches = plt.hist((P_test-M_1-M_2 - M_3).reshape(-1,1), 18, density=True, facecolor='y', \n",
    "                            alpha=0.85, label=\"Distribution of $\\pi - M^1_N$\")\n",
    "\n",
    "plt.grid(linestyle='-', linewidth=0.2, color='black')\n",
    "plt.tick_params(\n",
    "    axis='y',\n",
    "    color = 'w',\n",
    "    labelcolor = 'w',\n",
    "    which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# generate some random test data\n",
    "all_data = [P_test, P_test - M_1,P_test - M_1 -M_2,P_test - M_1 - M_2 - M_3]\n",
    "\n",
    "# plot violin plot\n",
    "plt.boxplot(all_data)\n",
    "plt.title('violin plot')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
